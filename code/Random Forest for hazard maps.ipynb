{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8591ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "# Import Python 3's print function and division\n",
    "from __future__ import print_function, division\n",
    "\n",
    "#Loading data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import OrderedDict\n",
    "\n",
    "cmaps = OrderedDict()\n",
    "\n",
    "#metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import recall_score,precision_score, cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, \\\n",
    "            classification_report, recall_score, precision_recall_curve\n",
    "\n",
    "#cross validations\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "\n",
    "# Define random state\n",
    "random_state = 2019\n",
    "np.random.seed(random_state)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#librerias de sistema\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# latex parameter\n",
    "font = {\n",
    "    'family': 'serif', \n",
    "    'serif': ['Computer Modern Roman'],\n",
    "    'weight' : 'regular',\n",
    "    'size'   : 8\n",
    "    }\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9fbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope --    CTE\n",
    "#soil type---CTE\n",
    "#land use ---- Variable \n",
    "#Bearing capacity .. simulate scenarios for 2007 starting from 1999 bearing capacity map\n",
    "\n",
    "#Hazard level 2001 for training and 2007 for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b46bd",
   "metadata": {},
   "source": [
    "<img src=\"D:/Proyectos_GitHub/PISCO_Peligro/img/idea_1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ef6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bajo 1\n",
    "#Medio 2\n",
    "#Alto 3\n",
    "#Muy Alto 4\n",
    "\n",
    "#### TIPOS de Suel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9ea61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_ensemble(object):\n",
    "    def __init__(self, n_splits, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.base_models = base_models\n",
    "        self.metriks={}\n",
    "        self.RE=[]\n",
    "        self.F1=[]\n",
    "        self.PRE=[]#\n",
    "\n",
    "    def predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "        no_class = len(np.unique(y))\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, \n",
    "                                     random_state = random_state).split(X, y))\n",
    "\n",
    "        train_proba = np.zeros((X.shape[0], no_class))\n",
    "        test_proba = np.zeros((T.shape[0], no_class))\n",
    "        \n",
    "        train_pred = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        test_pred = np.zeros((T.shape[0], len(self.base_models)* self.n_splits))\n",
    "        f1_scores = np.zeros((len(self.base_models), self.n_splits))\n",
    "        recall_scores = np.zeros((len(self.base_models), self.n_splits))\n",
    "        \n",
    "        test_col = 0\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            \n",
    "            for j, (train_idx, valid_idx) in enumerate(folds):\n",
    "                \n",
    "                X_train = X[train_idx]\n",
    "                Y_train = y[train_idx]\n",
    "                X_valid = X[valid_idx]\n",
    "                Y_valid = y[valid_idx]\n",
    "                \n",
    "                clf.fit(X_train, Y_train)\n",
    "                \n",
    "                valid_pred = clf.predict(X_valid)\n",
    "                recall  = recall_score(Y_valid, valid_pred, average='macro')\n",
    "                precision=precision_score(Y_valid,valid_pred,average='macro')#\n",
    "                f1 = f1_score(Y_valid, valid_pred, average='macro')\n",
    "                \n",
    "                recall_scores[i][j] = recall\n",
    "                f1_scores[i][j] = f1\n",
    "                \n",
    "                train_pred[valid_idx, i] = valid_pred\n",
    "                test_pred[:, test_col] = clf.predict(T)\n",
    "                test_col += 1\n",
    "                \n",
    "                ## Probabilities\n",
    "                valid_proba = clf.predict_proba(X_valid)\n",
    "                train_proba[valid_idx, :] = valid_proba\n",
    "                test_proba  += clf.predict_proba(T)\n",
    "                \n",
    "                self.RE.append(recall)\n",
    "                self.F1.append(f1)\n",
    "                self.PRE.append(precision)#\n",
    "                print( \"Model- {} and CV- {} recall: {}, precision: {}, f1_score: {}\".format(i, j, recall,precision, f1))\n",
    "                \n",
    "            test_proba /= self.n_splits\n",
    "            self.metriks['recall']=self.RE\n",
    "            self.metriks['f1']=self.F1\n",
    "            self.metriks['precision']=self.PRE#\n",
    "            \n",
    "        return train_proba, test_proba, train_pred, test_pred,self.metriks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d957",
   "metadata": {},
   "source": [
    "# Loading Data and splitting it into 80% training and 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5305930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:/Proyectos_GitHub/PISCO_Peligro/data/CSV/data.csv')\n",
    "features=data.iloc[:,0:4]\n",
    "target=data.loc[:,'hazard_value']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9281ac7",
   "metadata": {},
   "source": [
    "# Best parameters grid search for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08487689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  84 | elapsed:   10.8s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  84 | elapsed:   14.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, n_estimators=350, random_state=2019)\n",
      "{'n_estimators': 350, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits = 3, shuffle=True, random_state = random_state)\n",
    "\n",
    "rdf = RandomForestClassifier(random_state = random_state) \n",
    "scoring = {'Recall': make_scorer(recall_score),\n",
    "           'f1_score': make_scorer(f1_score)\n",
    "          }\n",
    "\n",
    "params = {'max_depth': [5, 10, 20,30], \n",
    "              'n_estimators' : [200,250,300,350,400,450,500]\n",
    "             }\n",
    "grid_clf= RandomizedSearchCV(estimator = rdf, param_distributions = params, n_iter = 50, cv = cv, verbose=4, n_jobs = -1)\n",
    "#grid_clf = GridSearchCV(estimator = rdf, param_grid = params, cv = cv, n_jobs=-1, verbose=4)\n",
    "grid_clf.fit(xtrain, ytrain)\n",
    "\n",
    "print(grid_clf.best_estimator_)\n",
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d31fa",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e1d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model- 0 and CV- 0 recall: 0.8504330228323599, precision: 0.878799431282086, f1_score: 0.8635543209160872\n",
      "Model- 0 and CV- 1 recall: 0.8408767944840078, precision: 0.8487704072449835, f1_score: 0.8447276180464401\n",
      "Model- 0 and CV- 2 recall: 0.8364306962112003, precision: 0.8767947533190457, f1_score: 0.8543920134367721\n",
      "Model- 0 and CV- 3 recall: 0.8043701994387465, precision: 0.8886374413415353, f1_score: 0.8365417260900726\n",
      "Model- 0 and CV- 4 recall: 0.80965812156929, precision: 0.8865218245499936, f1_score: 0.8399254279876885\n"
     ]
    }
   ],
   "source": [
    "rdf = RandomForestClassifier(bootstrap=True, criterion='gini',\n",
    "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=-1,\n",
    "            oob_score=False,\n",
    "            random_state=random_state,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "base_models = [rdf]\n",
    "n_splits = 5\n",
    "rf_stack = Create_ensemble(n_splits = n_splits, base_models = base_models)     \n",
    "train_proba, test_proba, train_pred, test_pred,indi_rf = rf_stack.predict(xtrain, ytrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4d8a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The F-1 score of the model 0.8481845352251338\n",
      "\n",
      "2. The recall score of the model 0.8284159179167331\n",
      "\n",
      "3. Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.98      0.98      9867\n",
      "           3       0.98      0.98      0.98     15359\n",
      "           4       0.67      0.53      0.59       342\n",
      "\n",
      "    accuracy                           0.97     25568\n",
      "   macro avg       0.87      0.83      0.85     25568\n",
      "weighted avg       0.97      0.97      0.97     25568\n",
      " \n",
      "\n",
      "4. Confusion matrix \n",
      " [[ 9668   194     5]\n",
      " [  237 15038    84]\n",
      " [   33   129   180]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1. The F-1 score of the model {}\\n'.format(f1_score(ytrain, train_pred, average='macro')))\n",
    "print('2. The recall score of the model {}\\n'.format(recall_score(ytrain, train_pred, average='macro')))\n",
    "print('3. Classification report \\n {} \\n'.format(classification_report(ytrain, train_pred)))\n",
    "print('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(ytrain, train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a7b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
